{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Dataset\n",
        "from azureml.core import Workspace\n",
        "import pandas as pd\n",
        "from io import StringIO\n",
        "\n",
        "workspace = Workspace.from_config()\n",
        "\n",
        "datastore = workspace.get_default_datastore()\n",
        "\n",
        "data = \"\"\" age, income, target\n",
        "25,50000,0\n",
        "30,60000,1\n",
        "35, 55000,0\n",
        "40, 65000, 1\n",
        "\"\"\"\n",
        "dataset_file = StringIO(data)\n",
        "\n",
        "df = pd.read_csv(dataset_file)\n",
        "df.to_csv(\"training_data.csv\", index=False)\n",
        "\n",
        "datastore.upload_files([\"training_data.csv\"], target_path=\"data/\", overwrite=True)\n",
        "\n",
        "dataset = Dataset.Tabular.from_delimited_files(path=(datastore,\"data/training_data.csv\"))\n",
        "dataset = dataset.register(workspace=workspace, name='training_dataset', create_new_version=True)\n",
        "print(\"dataset registered succesfully.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Uploading an estimated of 1 files\nUploading training_data.csv\nUploaded training_data.csv, 1 files out of an estimated total of 1\nUploaded 1 files\ndataset registered succesfully.\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1759577796647
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "\n",
        "# Set up logging to a file\n",
        "logging.basicConfig(filename='ml_pipeline.log', level=logging.INFO)\n",
        "\n",
        "# Example log message\n",
        "logging.info(\"Logging setup complete.\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Log the start of data loading\n",
        "logging.info(\"Loading dataset...\")\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('your-dataset.csv')\n",
        "logging.info(\"Dataset loaded successfully.\")\n",
        "\n",
        "# Log the start of preprocessing\n",
        "logging.info(\"Starting data preprocessing...\")\n",
        "\n",
        "# Example preprocessing: handling missing values\n",
        "df.fillna(0, inplace=True)\n",
        "logging.info(\"Missing values filled with 0.\")\n",
        "\n",
        "# Log the completion of preprocessing\n",
        "logging.info(\"Data preprocessing completed.\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Log the start of model training\n",
        "logging.info(\"Starting model training...\")\n",
        "\n",
        "try:\n",
        "    # Train the decision tree model\n",
        "    model = DecisionTreeClassifier()\n",
        "    model.fit(X_train, y_train)\n",
        "    logging.info(\"Model trained successfully.\")\n",
        "except Exception as e:\n",
        "    logging.error(f\"Error during model training: {e}\")\n",
        "\n",
        "# Example logging of training accuracy (if applicable)\n",
        "accuracy = model.score(X_train, y_train)\n",
        "logging.info(f\"Training accuracy: {accuracy:.2f}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Log the start of predictions\n",
        "logging.info(\"Starting model predictions...\")\n",
        "\n",
        "try:\n",
        "    # Make predictions\n",
        "    predictions = model.predict(X_test)\n",
        "    logging.info(\"Predictions made successfully.\")\n",
        "except Exception as e:\n",
        "    logging.error(f\"Error during predictions: {e}\")\n",
        "\n",
        "# Log the output (in production systems, limit the amount of data logged)\n",
        "logging.info(f\"Prediction output: {predictions[:5]}\")  # Log only first 5 predictions"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: logging an exception during data validation\n",
        "def validate_data(data):\n",
        "    try:\n",
        "        if not isinstance(data, pd.DataFrame):\n",
        "            raise ValueError(\"Input must be a pandas DataFrame.\")\n",
        "        logging.info(\"Data validation successful.\")\n",
        "    except ValueError as e:\n",
        "        logging.error(f\"Data validation error: {e}\")\n",
        "\n",
        "# Validate the dataset\n",
        "validate_data(df)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.10 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}